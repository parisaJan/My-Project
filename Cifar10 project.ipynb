{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1870b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the neural network architecture (you can replace this with your own architecture)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Define your layers here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass\n",
    "        return x\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "# Function to train and evaluate a model\n",
    "def train_and_evaluate(model, optimizer, criterion, num_epochs=10):\n",
    "    model.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Accuracy on test set: {100 * accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10067abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1563/1563 [==============================] - 114s 68ms/step - loss: 2.0350 - accuracy: 0.2628 - val_loss: 1.8297 - val_accuracy: 0.3518\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.6366 - accuracy: 0.4158 - val_loss: 1.5447 - val_accuracy: 0.4530\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.4349 - accuracy: 0.4869 - val_loss: 1.4071 - val_accuracy: 0.4926\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 1.3313 - accuracy: 0.5281 - val_loss: 1.2946 - val_accuracy: 0.5399\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 1.2539 - accuracy: 0.5580 - val_loss: 1.3399 - val_accuracy: 0.5220\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 75s 48ms/step - loss: 1.1814 - accuracy: 0.5847 - val_loss: 1.2496 - val_accuracy: 0.5599\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 79s 50ms/step - loss: 1.1176 - accuracy: 0.6089 - val_loss: 1.1179 - val_accuracy: 0.6101\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.0603 - accuracy: 0.6320 - val_loss: 1.1373 - val_accuracy: 0.6025\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 73s 46ms/step - loss: 1.0143 - accuracy: 0.6465 - val_loss: 1.0644 - val_accuracy: 0.6256\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.9715 - accuracy: 0.6627 - val_loss: 1.0590 - val_accuracy: 0.6316\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 110s 65ms/step - loss: 1.4196 - accuracy: 0.4912 - val_loss: 1.2241 - val_accuracy: 0.5605\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 82s 52ms/step - loss: 1.0667 - accuracy: 0.6265 - val_loss: 1.0351 - val_accuracy: 0.6440\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 80s 51ms/step - loss: 0.9456 - accuracy: 0.6716 - val_loss: 0.9644 - val_accuracy: 0.6693\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 0.8571 - accuracy: 0.7017 - val_loss: 0.9402 - val_accuracy: 0.6789\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.6355 - accuracy: 0.7787 - val_loss: 0.9148 - val_accuracy: 0.7041\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5987 - accuracy: 0.7912 - val_loss: 0.9487 - val_accuracy: 0.6928\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 73s 47ms/step - loss: 0.5577 - accuracy: 0.8029 - val_loss: 0.9762 - val_accuracy: 0.7011\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "# Data Loading and Preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Model Architecture\n",
    "def create_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Baseline Experiment (SGD)\n",
    "model_sgd = create_cnn_model()\n",
    "model_sgd.compile(optimizer=SGD(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_sgd = model_sgd.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Adam Experiment\n",
    "model_adam = create_cnn_model()\n",
    "model_adam.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_adam = model_adam.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# RMSprop Experiment\n",
    "model_rmsprop = create_cnn_model()\n",
    "model_rmsprop.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_rmsprop = model_rmsprop.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Comparative Analysis\n",
    "plt.plot(history_sgd.history['accuracy'], label='SGD Accuracy')\n",
    "plt.plot(history_adam.history['accuracy'], label='Adam Accuracy')\n",
    "plt.plot(history_rmsprop.history['accuracy'], label='RMSprop Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a455a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "DeepConvModel(\n",
      "  (network): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout2d(p=0.2, inplace=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU()\n",
      "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Dropout2d(p=0.3, inplace=False)\n",
      "    (16): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU()\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU()\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (23): Dropout2d(p=0.4, inplace=False)\n",
      "    (24): Flatten(start_dim=1, end_dim=-1)\n",
      "    (25): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "    (26): ReLU()\n",
      "    (27): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (28): ReLU()\n",
      "    (29): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as func\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class DeepConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            nn.Dropout2d(p=0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            nn.Dropout2d(p=0.3),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            nn.Dropout2d(p=0.4),\n",
    "\n",
    "            nn.Flatten(), \n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "deepconvmodel = DeepConvModel().to(device)\n",
    "\n",
    "print(deepconvmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f0f36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
